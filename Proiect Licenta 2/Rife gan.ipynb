{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARPLAYER\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "backwarp_tenGrid = {}\n",
    "\n",
    "def warp(tenInput, tenFlow):\n",
    "    k = (str(tenFlow.device), str(tenFlow.size()))\n",
    "    if k not in backwarp_tenGrid:\n",
    "        tenHorizontal = torch.linspace(-1.0, 1.0, tenFlow.shape[3], device=device).view(\n",
    "            1, 1, 1, tenFlow.shape[3]).expand(tenFlow.shape[0], -1, tenFlow.shape[2], -1)\n",
    "        tenVertical = torch.linspace(-1.0, 1.0, tenFlow.shape[2], device=device).view(\n",
    "            1, 1, tenFlow.shape[2], 1).expand(tenFlow.shape[0], -1, -1, tenFlow.shape[3])\n",
    "        backwarp_tenGrid[k] = torch.cat(\n",
    "            [tenHorizontal, tenVertical], 1).to(device)\n",
    "        \n",
    "    tenFlow = torch.cat([tenFlow[:, 0:1, :, :] / ((tenInput.shape[3] - 1.0) / 2.0),\n",
    "                         tenFlow[:, 1:2, :, :] / ((tenInput.shape[2] - 1.0) / 2.0)], 1)\n",
    "    \n",
    "    g = (backwarp_tenGrid[k] + tenFlow).permute(0,2,3,1)\n",
    "    return F.grid_sample(input=tenInput, grid = g, mode = 'bilinear', padding_mode='border', align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS\n",
    "\n",
    "class EPE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EPE, self).__init__()\n",
    "\n",
    "    def forward(self, flow, gt, loss_mask):\n",
    "        loss_map = (flow - gt.detach()) ** 2\n",
    "        loss_map = (loss_map.sum(1, True) + 1e-6) ** 0.5\n",
    "        return (loss_map * loss_mask)\n",
    "\n",
    "\n",
    "class Ternary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ternary, self).__init__()\n",
    "        patch_size = 7\n",
    "        out_channels = patch_size * patch_size\n",
    "        self.w = np.eye(out_channels).reshape(\n",
    "            (patch_size, patch_size, 1, out_channels))\n",
    "        self.w = np.transpose(self.w, (3, 2, 0, 1))\n",
    "        self.w = torch.tensor(self.w).float().to(device)\n",
    "\n",
    "    def transform(self, img):\n",
    "        patches = F.conv2d(img, self.w, padding=3, bias=None)\n",
    "        transf = patches - img\n",
    "        transf_norm = transf / torch.sqrt(0.81 + transf**2)\n",
    "        return transf_norm\n",
    "\n",
    "    def rgb2gray(self, rgb):\n",
    "        r, g, b = rgb[:, 0:1, :, :], rgb[:, 1:2, :, :], rgb[:, 2:3, :, :]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray\n",
    "\n",
    "    def hamming(self, t1, t2):\n",
    "        dist = (t1 - t2) ** 2\n",
    "        dist_norm = torch.mean(dist / (0.1 + dist), 1, True)\n",
    "        return dist_norm\n",
    "\n",
    "    def valid_mask(self, t, padding):\n",
    "        n, _, h, w = t.size()\n",
    "        inner = torch.ones(n, 1, h - 2 * padding, w - 2 * padding).type_as(t)\n",
    "        mask = F.pad(inner, [padding] * 4)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, img0, img1):\n",
    "        img0 = self.transform(self.rgb2gray(img0))\n",
    "        img1 = self.transform(self.rgb2gray(img1))\n",
    "        return self.hamming(img0, img1) * self.valid_mask(img0, 1)\n",
    "\n",
    "\n",
    "class SOBEL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SOBEL, self).__init__()\n",
    "        self.kernelX = torch.tensor([\n",
    "            [1, 0, -1],\n",
    "            [2, 0, -2],\n",
    "            [1, 0, -1],\n",
    "        ]).float()\n",
    "        self.kernelY = self.kernelX.clone().T\n",
    "        self.kernelX = self.kernelX.unsqueeze(0).unsqueeze(0).to(device)\n",
    "        self.kernelY = self.kernelY.unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        N, C, H, W = pred.shape[0], pred.shape[1], pred.shape[2], pred.shape[3]\n",
    "        img_stack = torch.cat(\n",
    "            [pred.reshape(N*C, 1, H, W), gt.reshape(N*C, 1, H, W)], 0)\n",
    "        sobel_stack_x = F.conv2d(img_stack, self.kernelX, padding=1)\n",
    "        sobel_stack_y = F.conv2d(img_stack, self.kernelY, padding=1)\n",
    "        pred_X, gt_X = sobel_stack_x[:N*C], sobel_stack_x[N*C:]\n",
    "        pred_Y, gt_Y = sobel_stack_y[:N*C], sobel_stack_y[N*C:]\n",
    "\n",
    "        L1X, L1Y = torch.abs(pred_X-gt_X), torch.abs(pred_Y-gt_Y)\n",
    "        loss = (L1X+L1Y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IFNet MODEL\n",
    "\n",
    "def conv_wo_act(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                  padding=padding, dilation=dilation, bias=True),\n",
    "    )\n",
    "\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                  padding=padding, dilation=dilation, bias=True),\n",
    "        nn.PReLU(out_planes)\n",
    "    )\n",
    "\n",
    "#Block pt retea\n",
    "class IFBlock(nn.Module):\n",
    "    def __init__(self, in_planes, scale=1, c=64):\n",
    "        super(IFBlock, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.conv0 = nn.Sequential(\n",
    "            conv(in_planes, c, 3, 2, 1),\n",
    "            conv(c, 2*c, 3, 2, 1),\n",
    "            )\n",
    "        self.convblock = nn.Sequential(\n",
    "            conv(2*c, 2*c),\n",
    "            conv(2*c, 2*c),\n",
    "            conv(2*c, 2*c),\n",
    "            conv(2*c, 2*c),\n",
    "            conv(2*c, 2*c),\n",
    "            conv(2*c, 2*c),\n",
    "        )        \n",
    "        self.conv1 = nn.ConvTranspose2d(2*c, 4, 4, 2, 1)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        if self.scale != 1:\n",
    "            x = F.interpolate(x, scale_factor=1. / self.scale, mode=\"bilinear\",\n",
    "                              align_corners=False)\n",
    "        x = self.conv0(x)\n",
    "        x = self.convblock(x)\n",
    "        x = self.conv1(x)\n",
    "        flow = x\n",
    "        if self.scale != 1:\n",
    "            flow = F.interpolate(flow, scale_factor=self.scale, mode=\"bilinear\",\n",
    "                                 align_corners=False)\n",
    "        return flow\n",
    "\n",
    "#reteaua ifnet\n",
    "class IFNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IFNet, self).__init__()\n",
    "        self.block0 = IFBlock(6, scale=8, c=192)\n",
    "        self.block1 = IFBlock(10, scale=4, c=128)\n",
    "        self.block2 = IFBlock(10, scale=2, c=96)\n",
    "        self.block3 = IFBlock(10, scale=1, c=48)\n",
    "\n",
    "    def forward(self, x, scale=1.0):\n",
    "        if scale != 1.0:\n",
    "            x = F.interpolate(x, scale_factor=scale, mode=\"bilinear\", align_corners=False)\n",
    "        flow0 = self.block0(x)\n",
    "        F1 = flow0\n",
    "        F1_large = F.interpolate(F1, scale_factor=2.0, mode=\"bilinear\", align_corners=False) * 2.0\n",
    "        warped_img0 = warp(x[:, :3], F1_large[:, :2])\n",
    "        warped_img1 = warp(x[:, 3:], F1_large[:, 2:4])\n",
    "        flow1 = self.block1(torch.cat((warped_img0, warped_img1, F1_large), 1))\n",
    "        F2 = (flow0 + flow1)\n",
    "        F2_large = F.interpolate(F2, scale_factor=2.0, mode=\"bilinear\", align_corners=False) * 2.0\n",
    "        warped_img0 = warp(x[:, :3], F2_large[:, :2])\n",
    "        warped_img1 = warp(x[:, 3:], F2_large[:, 2:4])\n",
    "        flow2 = self.block2(torch.cat((warped_img0, warped_img1, F2_large), 1))\n",
    "        F3 = (flow0 + flow1 + flow2)\n",
    "        F3_large = F.interpolate(F3, scale_factor=2.0, mode=\"bilinear\", align_corners=False) * 2.0\n",
    "        warped_img0 = warp(x[:, :3], F3_large[:, :2])\n",
    "        warped_img1 = warp(x[:, 3:], F3_large[:, 2:4])\n",
    "        flow3 = self.block3(torch.cat((warped_img0, warped_img1, F3_large), 1))\n",
    "        F4 = (flow0 + flow1 + flow2 + flow3)\n",
    "        if scale != 1.0:\n",
    "            F4 = F.interpolate(F4, scale_factor=1 / scale, mode=\"bilinear\", align_corners=False) / scale\n",
    "        return F4, [F1, F2, F3, F4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIFE MODEL\n",
    "\n",
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                  padding=padding, dilation=dilation, bias=True),\n",
    "        nn.PReLU(out_planes)\n",
    "    )\n",
    "\n",
    "\n",
    "def deconv(in_planes, out_planes, kernel_size=4, stride=2, padding=1):\n",
    "    return nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(in_channels=in_planes, out_channels=out_planes,\n",
    "                                 kernel_size=4, stride=2, padding=1, bias=True),\n",
    "        nn.PReLU(out_planes)\n",
    "    )\n",
    "\n",
    "def conv_woact(in_planes, out_planes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride,\n",
    "                  padding=padding, dilation=dilation, bias=True),\n",
    "    )\n",
    "\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=2):\n",
    "        super(Conv2, self).__init__()\n",
    "        self.conv1 = conv(in_planes, out_planes, 3, stride, 1)\n",
    "        self.conv2 = conv(out_planes, out_planes, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "c = 32\n",
    "\n",
    "class ContextNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContextNet, self).__init__()\n",
    "        self.conv0 = Conv2(3, c)\n",
    "        self.conv1 = Conv2(c, c)\n",
    "        self.conv2 = Conv2(c, 2*c)\n",
    "        self.conv3 = Conv2(2*c, 4*c)\n",
    "        self.conv4 = Conv2(4*c, 8*c)\n",
    "\n",
    "    def forward(self, x, flow):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        flow = F.interpolate(flow, scale_factor=0.5, mode=\"bilinear\", align_corners=False) * 0.5\n",
    "        f1 = warp(x, flow)\n",
    "        x = self.conv2(x)\n",
    "        flow = F.interpolate(flow, scale_factor=0.5, mode=\"bilinear\",\n",
    "                             align_corners=False) * 0.5\n",
    "        f2 = warp(x, flow)\n",
    "        x = self.conv3(x)\n",
    "        flow = F.interpolate(flow, scale_factor=0.5, mode=\"bilinear\",\n",
    "                             align_corners=False) * 0.5\n",
    "        f3 = warp(x, flow)\n",
    "        x = self.conv4(x)\n",
    "        flow = F.interpolate(flow, scale_factor=0.5, mode=\"bilinear\",\n",
    "                             align_corners=False) * 0.5\n",
    "        f4 = warp(x, flow)\n",
    "        return [f1, f2, f3, f4]\n",
    "\n",
    "\n",
    "class FusionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FusionNet, self).__init__()\n",
    "        self.conv0 = Conv2(10, c)\n",
    "        self.down0 = Conv2(c, 2*c)\n",
    "        self.down1 = Conv2(4*c, 4*c)\n",
    "        self.down2 = Conv2(8*c, 8*c)\n",
    "        self.down3 = Conv2(16*c, 16*c)\n",
    "        self.up0 = deconv(32*c, 8*c)\n",
    "        self.up1 = deconv(16*c, 4*c)\n",
    "        self.up2 = deconv(8*c, 2*c)\n",
    "        self.up3 = deconv(4*c, c)\n",
    "        self.conv = nn.ConvTranspose2d(c, 4, 4, 2, 1)\n",
    "\n",
    "    def forward(self, img0, img1, flow, c0, c1, flow_gt):\n",
    "        warped_img0 = warp(img0, flow[:, :2])\n",
    "        warped_img1 = warp(img1, flow[:, 2:4])\n",
    "        if flow_gt == None:\n",
    "            warped_img0_gt, warped_img1_gt = None, None\n",
    "        else:\n",
    "            warped_img0_gt = warp(img0, flow_gt[:, :2])\n",
    "            warped_img1_gt = warp(img1, flow_gt[:, 2:4])\n",
    "        x = self.conv0(torch.cat((warped_img0, warped_img1, flow), 1))\n",
    "        s0 = self.down0(x)\n",
    "        s1 = self.down1(torch.cat((s0, c0[0], c1[0]), 1))\n",
    "        s2 = self.down2(torch.cat((s1, c0[1], c1[1]), 1))\n",
    "        s3 = self.down3(torch.cat((s2, c0[2], c1[2]), 1))\n",
    "        x = self.up0(torch.cat((s3, c0[3], c1[3]), 1))\n",
    "        x = self.up1(torch.cat((x, s2), 1))\n",
    "        x = self.up2(torch.cat((x, s1), 1))\n",
    "        x = self.up3(torch.cat((x, s0), 1))\n",
    "        x = self.conv(x)\n",
    "        return x, warped_img0, warped_img1, warped_img0_gt, warped_img1_gt\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, local_rank=-1):\n",
    "        self.flownet = IFNet()\n",
    "        self.contextnet = ContextNet()\n",
    "        self.fusionnet = FusionNet()\n",
    "        self.device()\n",
    "        self.optimG = AdamW(itertools.chain(\n",
    "            self.flownet.parameters(),\n",
    "            self.contextnet.parameters(),\n",
    "            self.fusionnet.parameters()), lr=1e-6, weight_decay=1e-5)\n",
    "        self.schedulerG = optim.lr_scheduler.CyclicLR(\n",
    "            self.optimG, base_lr=1e-6, max_lr=1e-3, step_size_up=8000, cycle_momentum=False)\n",
    "        self.epe = EPE()\n",
    "        self.ter = Ternary()\n",
    "        self.sobel = SOBEL()\n",
    "        if local_rank != -1:\n",
    "            self.flownet = DDP(self.flownet, device_ids=[\n",
    "                               local_rank], output_device=local_rank)\n",
    "            self.contextnet = DDP(self.contextnet, device_ids=[\n",
    "                                  local_rank], output_device=local_rank)\n",
    "            self.fusionnet = DDP(self.fusionnet, device_ids=[\n",
    "                                 local_rank], output_device=local_rank)\n",
    "\n",
    "    def train(self):\n",
    "        self.flownet.train()\n",
    "        self.contextnet.train()\n",
    "        self.fusionnet.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.flownet.eval()\n",
    "        self.contextnet.eval()\n",
    "        self.fusionnet.eval()\n",
    "\n",
    "    def device(self):\n",
    "        self.flownet.to(device)\n",
    "        self.contextnet.to(device)\n",
    "        self.fusionnet.to(device)\n",
    "\n",
    "    def load_model(self, path, rank):\n",
    "        def convert(param):\n",
    "            if rank == -1:\n",
    "                return {\n",
    "                    k.replace(\"module.\", \"\"): v\n",
    "                    for k, v in param.items()\n",
    "                    if \"module.\" in k\n",
    "                }\n",
    "            else:\n",
    "                return param\n",
    "        if rank <= 0:\n",
    "            self.flownet.load_state_dict(\n",
    "                convert(torch.load('{}/flownet.pkl'.format(path), map_location=device)))\n",
    "            self.contextnet.load_state_dict(\n",
    "                convert(torch.load('{}/contextnet.pkl'.format(path), map_location=device)))\n",
    "            self.fusionnet.load_state_dict(\n",
    "                convert(torch.load('{}/unet.pkl'.format(path), map_location=device)))\n",
    "\n",
    "    def save_model(self, path, rank):\n",
    "        if rank == 0:\n",
    "            torch.save(self.flownet.state_dict(), '{}/flownet.pkl'.format(path))\n",
    "            torch.save(self.contextnet.state_dict(), '{}/contextnet.pkl'.format(path))\n",
    "            torch.save(self.fusionnet.state_dict(), '{}/unet.pkl'.format(path))\n",
    "\n",
    "    def predict(self, imgs, flow, training=True, flow_gt=None):\n",
    "        img0 = imgs[:, :3]\n",
    "        img1 = imgs[:, 3:]\n",
    "        c0 = self.contextnet(img0, flow[:, :2])\n",
    "        c1 = self.contextnet(img1, flow[:, 2:4])\n",
    "        flow = F.interpolate(flow, scale_factor=2.0, mode=\"bilinear\",\n",
    "                             align_corners=False) * 2.0\n",
    "        refine_output, warped_img0, warped_img1, warped_img0_gt, warped_img1_gt = self.fusionnet(\n",
    "            img0, img1, flow, c0, c1, flow_gt)\n",
    "        res = torch.sigmoid(refine_output[:, :3]) * 2 - 1\n",
    "        mask = torch.sigmoid(refine_output[:, 3:4])\n",
    "        merged_img = warped_img0 * mask + warped_img1 * (1 - mask)\n",
    "        pred = merged_img + res\n",
    "        pred = torch.clamp(pred, 0, 1)\n",
    "        if training:\n",
    "            return pred, mask, merged_img, warped_img0, warped_img1, warped_img0_gt, warped_img1_gt\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def inference(self, img0, img1, scale=1.0):\n",
    "        imgs = torch.cat((img0, img1), 1)\n",
    "        flow, _ = self.flownet(imgs, scale)\n",
    "        return self.predict(imgs, flow, training=False)\n",
    "\n",
    "    def update(self, imgs, gt, learning_rate=0, mul=1, training=True, flow_gt=None):\n",
    "        for param_group in self.optimG.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "        if training:\n",
    "            self.train()\n",
    "        else:\n",
    "            self.eval()\n",
    "        flow, flow_list = self.flownet(imgs)\n",
    "        pred, mask, merged_img, warped_img0, warped_img1, warped_img0_gt, warped_img1_gt = self.predict(\n",
    "            imgs, flow, flow_gt=flow_gt)\n",
    "        loss_ter = self.ter(pred, gt).mean()\n",
    "        if training:\n",
    "            with torch.no_grad():\n",
    "                loss_flow = torch.abs(warped_img0_gt - gt).mean()\n",
    "                loss_mask = torch.abs(\n",
    "                    merged_img - gt).sum(1, True).float().detach()\n",
    "                loss_mask = F.interpolate(loss_mask, scale_factor=0.5, mode=\"bilinear\",\n",
    "                                          align_corners=False).detach()\n",
    "                flow_gt = (F.interpolate(flow_gt, scale_factor=0.5, mode=\"bilinear\",\n",
    "                                         align_corners=False) * 0.5).detach()\n",
    "            loss_cons = 0\n",
    "            for i in range(4):\n",
    "                loss_cons += self.epe(flow_list[i][:, :2], flow_gt[:, :2], 1)\n",
    "                loss_cons += self.epe(flow_list[i][:, 2:4], flow_gt[:, 2:4], 1)\n",
    "            loss_cons = loss_cons.mean() * 0.01\n",
    "        else:\n",
    "            loss_cons = torch.tensor([0])\n",
    "            loss_flow = torch.abs(warped_img0 - gt).mean()\n",
    "            loss_mask = 1\n",
    "        loss_l1 = (((pred - gt) ** 2 + 1e-6) ** 0.5).mean()\n",
    "        if training:\n",
    "            self.optimG.zero_grad()\n",
    "            loss_G = loss_l1 + loss_cons + loss_ter\n",
    "            loss_G.backward()\n",
    "            self.optimG.step()\n",
    "        return pred, merged_img, flow, loss_l1, loss_flow, loss_cons, loss_ter, loss_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
