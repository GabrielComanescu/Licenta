{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n",
    "\n",
    "def train_hr_transform(crop_size):\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomCrop(crop_size),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "def train_lr_transform(crop_size, upscale_factor):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(crop_size // upscale_factor, interpolation = Image.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "def display_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(400),\n",
    "        transforms.CenterCrop(400),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "class TrainDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        super(TrainDatasetFromFolder, self).__init__()\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.hr_transform = train_hr_transform(crop_size)\n",
    "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
    "        lr_image = self.lr_transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "class ValDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(ValDatasetFromFolder, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        hr_image = Image.open(self.image_filenames[index])\n",
    "        w, h = hr_image.size\n",
    "        crop_size = calculate_valid_crop_size(min(w,h),self.upscale_factor)\n",
    "        lr_scale = transforms.Resize(crop_size // self.upscale_factor, interpolation = Image.BICUBIC)\n",
    "        hr_scale = transforms.Resize(crop_size, interpolation = Image.BICUBIC)\n",
    "        hr_image = transforms.CenterCrop(crop_size)(hr_image)\n",
    "        lr_image = lr_scale(hr_image)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return transforms.ToTensor()(lr_image), transforms.ToTensor()(hr_restore_img), transforms.ToTensor()(hr_image)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "class TestDatasetFromFolder(Dataset):\n",
    "    def __init__(self, dataset_dir, upscale_factor):\n",
    "        super(TestDatasetFromFolder, self).__init__()\n",
    "        self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
    "        self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
    "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.lr_filenames[index].split('/')[-1]\n",
    "        lr_image = Image.open(self.lr_filenames[index])\n",
    "        w,h = lr_image.size\n",
    "        hr_image = Image.open(self.hr_filenames[index])\n",
    "        hr_scale = transforms.Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
    "        hr_restore_img = hr_scale(lr_image)\n",
    "        return image_name, transforms.ToTensor()(lr_image), transforms.ToTensor()(hr_restore_img), transforms.ToTensor()(hr_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GeneratorLoss(\n  (loss_network): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): ReLU(inplace=True)\n    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): ReLU(inplace=True)\n    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (mse_loss): MSELoss()\n  (tv_loss): TVLoss()\n)\n"
     ]
    }
   ],
   "source": [
    "# LOSS\n",
    "\n",
    "from torchvision.models.vgg import vgg19\n",
    "\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg19(pretrained = True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "        \n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "    \n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:] - x[:,:,:h_x - 1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:] - x[:,:,:,:w_x - 1]),2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    g_loss = GeneratorLoss()\n",
    "    print(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIDUAL BLOCK\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels,channels, kernel_size=3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.prelu(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "        \n",
    "        return x + residual\n",
    "    \n",
    "    \n",
    "    \n",
    "# UPSAMPLE BLOCK\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self,in_channels, up_scale):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        self.prelu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "# GENERATOR\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, scale_factor):\n",
    "        upsample_block_num = int(math.log(scale_factor,2))\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(nn.Conv2d(3,64,kernel_size=9,padding=4),nn.PReLU())\n",
    "        self.block2 = ResidualBlock(64)\n",
    "        self.block3 = ResidualBlock(64)\n",
    "        self.block4 = ResidualBlock(64)\n",
    "        self.block5 = ResidualBlock(64)\n",
    "        self.block6 = ResidualBlock(64)\n",
    "        self.block7 = nn.Sequential(nn.Conv2d(64,64,kernel_size=3,padding=1), nn.BatchNorm2d(64))\n",
    "        block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
    "        block8.append(nn.Conv2d(64,3,kernel_size=9,padding=4))\n",
    "        self.block8 = nn.Sequential(*block8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        block1 = self.block1(x)\n",
    "        block2 = self.block2(block1)\n",
    "        block3 = self.block3(block2)\n",
    "        block4 = self.block4(block3)\n",
    "        block5 = self.block5(block4)\n",
    "        block6 = self.block6(block5)\n",
    "        block7 = self.block7(block6)\n",
    "        block8 = self.block8(block1 + block7)\n",
    "        \n",
    "        return (torch.tanh(block8) + 1) / 2\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# DISCRIMINATOR\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(3,64,kernel_size=3,padding=1),\n",
    "                                 nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(64,64,kernel_size=3,stride=2,padding=1),\n",
    "                                nn.BatchNorm2d(64), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                \n",
    "                                nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
    "                                nn.BatchNorm2d(128), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(128,128,kernel_size=3,stride=2,padding=1),\n",
    "                                nn.BatchNorm2d(128), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(128,256,kernel_size=3,padding=1),\n",
    "                                nn.BatchNorm2d(256), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(256,256,kernel_size=3,stride=2,padding=1),\n",
    "                                nn.BatchNorm2d(256), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(256,512,kernel_size=3,padding=1),\n",
    "                                nn.BatchNorm2d(512), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.Conv2d(512,512,kernel_size=3,stride=2,padding=1),\n",
    "                                nn.BatchNorm2d(512), \n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                 \n",
    "                                nn.AdaptiveAvgPool2d(1),\n",
    "                                nn.Conv2d(512,1024,kernel_size=1),\n",
    "                                nn.LeakyReLU(0.2),\n",
    "                                nn.Conv2d(1024,1,kernel_size=1)\n",
    "                                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        return torch.sigmoid(self.net(x).view(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GeneratorLoss(\n",
       "  (loss_network): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (mse_loss): MSELoss()\n",
       "  (tv_loss): TVLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "netG = Generator(2).eval()\n",
    "netG.cuda()\n",
    "netG.load_state_dict(torch.load('modele/' + 'netG_epoch.pth'))\n",
    "\n",
    "netD = Discriminator().eval()\n",
    "netD.cuda()\n",
    "netD.load_state_dict(torch.load('modele/' + 'netD_epoch.pth'))\n",
    "\n",
    "generator_criterion = GeneratorLoss()\n",
    "generator_criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "UPSCALE_FACTOR = 2\n",
    "TEST_MODE = True\n",
    "IMAGE_NAME = 'pu.jpg'\n",
    "MODEL_NAME = 'netG_epoch.pth'\n",
    "\n",
    "model = Generator(UPSCALE_FACTOR).eval()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load('modele/' + MODEL_NAME))\n",
    "\n",
    "image = Image.open(IMAGE_NAME)\n",
    "image = Variable(transforms.ToTensor()(image)).unsqueeze(0)\n",
    "image = image.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(image)\n",
    "    \n",
    "out_img = ToPILImage()(out[0].data.cpu())\n",
    "out_img.save('test/' + str('20') + '_' + IMAGE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd04e68a42444b13db3bacd1cd6c46a066f96ab621132701a69454eeb8e1d76a336",
   "display_name": "Python 3.7.3 64-bit ('pytorchenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}